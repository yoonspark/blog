---
layout: post
title: Centralized Data Management vs. Reproducibility
---

In [my previous post](https://yoonspark.github.io/blog/2018/02/11/organizing-project-directory.html), I argued that reproducible research requires integrity and self-sufficiency of each individual project directory.  In particular, I highlighted the importance of raw data residing *within* each project directory.  This "self-containment" approach demands common raw data be potentially copied across different projects, and hence conflicts with the spirit of centralized data management.  From the organization's perspective, these "copies" may seem to not only waste memory resources but also create potential confusion about data versioning by, for instance, condoning use of outdated version of data.  However, I think the benefits of the "self-containment" approach much outweigh its costs.

Of course, the greatest benefit of the "self-containment" approach is that it allows for complete reproducibility of the entire project at any point of time, which would not be possible if the project depends and builds upon an external source that changes over time.  After all, the nature of data analysis is such that the analyst has to at some point decide and fix the specific form of raw data she is to use.  This "docking" then bestows integrity on the subsequent steps of analysis.  Imagine a series of analyses conducted using constantly updating raw data.  How can we then be sure that the conclusion from one analysis carries over to the next?  Therefore, using a "fixed" version of raw data is actually important for not only reproducibility but also integrity and validity of the entire project.

Concerns over memory waste are valid yet rather exaggerated.  First of all, computing technology has achieved such marvelous advances in recent decades that storing multiple copies of data should not be a dreadful thing.  More importantly, a project rarely requires the organization's entire raw data; more often, a project only requires a part of the organization's raw data to address its specific aim.  In other words, each project only requires a *partial* duplication.  As long as each "project" is defined at the appropriate scope and level (neither too small nor too big), the duplication will offer more benefits than costs.
